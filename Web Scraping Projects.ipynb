{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb9eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3069f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237a763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a62ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2909148a",
   "metadata": {},
   "source": [
    "# Display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a508ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "html = urlopen('https://en.wikipedia.org/wiki/Main_Page')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "titles = bs.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "print('List all the header tags :', *titles, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ecd4f",
   "metadata": {},
   "source": [
    "# Display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf6f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/chart/top/'\n",
    "page = requests.get(url)\n",
    "\n",
    "page.content\n",
    "soup = BeautifulSoup(page.content,\"html.parser\")\n",
    "#print(soup.prettify())\n",
    "\n",
    "scraped_movies = soup.find_all('td', class_='titleColumn')\n",
    "\n",
    "movies = []\n",
    "for movie in scraped_movies:\n",
    "    movie = movie.get_text().replace('\\n',\"\")\n",
    "    movie = movie.strip(\" \")                                 \n",
    "    movies.append(movie)\n",
    "\n",
    "\n",
    "scraped_ratings = soup.find_all('td', class_='ratingColumn imdbRating')\n",
    "\n",
    "ratings = []\n",
    "for rating in scraped_ratings:\n",
    "    rating = rating.get_text().replace('\\n','')\n",
    "    ratings.append(rating)\n",
    "\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['Movies Name'] = movies\n",
    "data['Rating'] = ratings\n",
    "\n",
    "data.head(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3503c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('IMDB Top Movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d290d1c",
   "metadata": {},
   "source": [
    "# Display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358cd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "page.content\n",
    "soup = BeautifulSoup(page.content,\"html.parser\")\n",
    "#print(soup.prettify())\n",
    "\n",
    "scraped_movies = soup.find_all('td', class_='titleColumn')\n",
    "\n",
    "movies = []\n",
    "for movie in scraped_movies:\n",
    "    movie = movie.get_text().replace('\\n',\"\")\n",
    "    movie = movie.strip(\" \")                                 \n",
    "    movies.append(movie)\n",
    "\n",
    "\n",
    "scraped_ratings = soup.find_all('td', class_='ratingColumn imdbRating')\n",
    "\n",
    "ratings = []\n",
    "for rating in scraped_ratings:\n",
    "    rating = rating.get_text().replace('\\n','')\n",
    "    ratings.append(rating)\n",
    "\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['Movies Name'] = movies\n",
    "data['Rating'] = ratings\n",
    "\n",
    "data.head(100)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c975c6",
   "metadata": {},
   "source": [
    "# python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content and the code for the video from the link for the youtube video from the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://coreyms.com/category/development'\n",
    "page = requests.get(url).text\n",
    "soup = BeautifulSoup(page, 'lxml')\n",
    "\n",
    "for article in soup.find_all('article'):\n",
    "    headline = article.a.text\n",
    "    print(headline)\n",
    "\n",
    "    summary = article.find('div', class_='entry-content').p.text\n",
    "    print(summary)    \n",
    "\n",
    "    vid_src = article.find('iframe', class_='youtube-player')['src']\n",
    "\n",
    "\n",
    "    vid_id = vid_src.split('/')[4]\n",
    "    vid_id = vid_id.split('?')[0]\n",
    "\n",
    "    yt_link = f'http://youtube.com/watch?v={vid_id}'\n",
    "    print(yt_link)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7380db9",
   "metadata": {},
   "source": [
    "# Python program to scrape weather details for last 24 hours from Tutiempo.net :Hour,Temperature,Wind,Weather condition,Humidity, Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1357d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# to get data from website\n",
    "file = requests.get(\"https://en.tutiempo.net/delhi.html?data=last-24-hours\")\n",
    "\n",
    "# import Beautifulsoup for scraping the data \n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(file.content, \"html.parser\")\n",
    "\n",
    "list =[]\n",
    "all = soup.find(\"td\",class_='sel').a.text \n",
    "\n",
    "for items in content:\n",
    "    for i in range(len(items.find_all(\"tr\"))-1):\n",
    "        dict = {}\n",
    "        try:\n",
    "            dict[\"weather\"]= items.find_all(\"span\",class_='weather-condition')[i].text            \n",
    "            dict[\"hour\"]= items.find_all(\"th\",class_='hour')[i].text\n",
    "            dict[\"temp\"]= items.find_all(\"th\", {\"class\":\"temp\"})[i].text\n",
    "            dict[\"pressure\"]= items.find_all(\"th\", {\"class\":\"pressure\"})[i].text\n",
    "            dict[\"wind\"]= items.find_all(\"th\", {\"class\":\"wind\"})[i].text\n",
    "            dict[\"humidity\"]= items.find_all(\"th\", {\"class\":\"humidity\"})[i].text\n",
    "        except:  \n",
    "            dict[\"weather\"]=\"None\"\n",
    "            dict[\"hour\"]=\"None\"\n",
    "            dict[\"temp\"]=\"None\"\n",
    "            dict[\"pressure\"]=\"None\"\n",
    "            dict[\"wind\"]=\"None\"\n",
    "            dict[\"humidity\"]=\"None\"\n",
    "            \n",
    "list.append(dict)\n",
    "         \n",
    "import pandas as pd\n",
    "convert = pd.DataFrame(all)\n",
    "print(all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c1aabb",
   "metadata": {},
   "source": [
    "# Python program to scrape monument name, monument description, image URL about top 10 monuments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8348c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4  import BeautifulSoup\n",
    "res = requests.get('https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india/')\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "monument_data = []\n",
    "for i in soup.find_all('div',class_='blog--single__content column--3-4 u-spacing-third'):\n",
    "    monument_data.append(i.text)\n",
    "print(monument_data) \n",
    "\n",
    "image = []\n",
    "for i in soup.find_all(\"img\", class_=\"img alt\"):\n",
    "    image.append(i[\"data-srcset\"])\n",
    "print(image)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae64d8",
   "metadata": {},
   "source": [
    "# Python program to scrape mentioned details from dineout.co.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb8cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page = requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "image = []\n",
    "for i in soup.find_all(\"img\", class_=\"no-img\"):\n",
    "    image.append(i[\"data-src\"])\n",
    "image\n",
    "\n",
    "restaurant_name = []\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-name ellipsis\"):\n",
    "    restaurant_name.append(i[\"href\"])\n",
    "restaurant_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0776f4e",
   "metadata": {},
   "source": [
    "# Python program to scrape cricket rankings from icc-cricket.com for men's cricket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95eec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/overview'\n",
    "page = requests.get(url)\n",
    "\n",
    "#page.content\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "players = []\n",
    "for i in soup.find_all(\"div\",class_='rankings-block__banner--name'):\n",
    "    players.append(i.text)\n",
    "for i in soup.find_all(\"td\", class_='table-body__cell name'):\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "print(players) \n",
    "\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['Player'] = players\n",
    "#data['Rating'] = ratings\n",
    "\n",
    "data.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c858166",
   "metadata": {},
   "source": [
    "# Python program to scrape cricket rankings from icc-cricket.com for women's cricket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/overview'\n",
    "page = requests.get(url)\n",
    "\n",
    "#page.content\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "players = []\n",
    "for i in soup.find_all(\"div\",class_='rankings-block__banner--name'):\n",
    "    players.append(i.text)\n",
    "for i in soup.find_all(\"td\", class_='table-body__cell name'):\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "print(players)\n",
    "\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['Player'] = players\n",
    "#data['Rating'] = ratings\n",
    "\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18eec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
